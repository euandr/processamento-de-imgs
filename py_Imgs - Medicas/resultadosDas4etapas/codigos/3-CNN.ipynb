{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, InceptionV3, EfficientNetB0, Xception, MobileNetV2\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77308a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para calcular as métricas\n",
    "def get_metrics(y_true, y_pred):\n",
    "    vn, fp, fn, vp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = (vp + vn) / (vp + fp + fn + vn)\n",
    "    recall = vp / (vp + fn)\n",
    "    specificity = vn / (vn + fp)\n",
    "    precision = vp / (vp + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'specificity': specificity,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1-score': f1,\n",
    "        'kappa': kappa,\n",
    "        'auc-roc': auc_roc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4672f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para seleção de esquema de cor \n",
    "def convert_color_scale(image, scale):\n",
    "    if scale == 'hsv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif scale == 'rgb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif scale == 'grayscale':\n",
    "        # Converter para escala de cinza e replicar para 3 canais\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.merge([gray, gray, gray])\n",
    "    elif scale == 'lab':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    elif scale == 'luv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif scale == 'xyz':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2XYZ)\n",
    "    elif scale == 'YcrCb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Escala de cor não suportada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0c6ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e pré-processamento de imagens com escolha de escala de cor\n",
    "def load_images(folder, color_scale, img_extensions):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if any(filename.lower().endswith(ext) for ext in img_extensions):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # Ajuste o tamanho conforme necessário\n",
    "\n",
    "                # Converta para a escala de cor desejada\n",
    "                img = convert_color_scale(img, color_scale)\n",
    "\n",
    "                # Se a imagem estiver em escala de cinza, expanda as dimensões\n",
    "                if color_scale == 'grayscale':\n",
    "                    img = np.expand_dims(img, axis=-1)  # Adiciona uma dimensão de canal\n",
    "\n",
    "                images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "582c5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina as pastas de dados\n",
    "data_dir = r\"C:\\Users\\andre\\Pictures\\OvarianCancer\"\n",
    "normal_dir = os.path.join(data_dir, 'Non_Cancerous')\n",
    "cancer_dir = os.path.join(data_dir, 'Serous')\n",
    "img_extensions = ['.jpg', '.jpeg', '.png']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc261eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab69e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para VGG16: (Com RF)\n",
      "{'accuracy': 0.85, 'specificity': 0.8, 'recall': 0.9, 'precision': 0.8181818181818182, 'f1-score': 0.8571428571428572, 'kappa': 0.7, 'auc-roc': 0.85}\n",
      "Métricas para ResNet50: (Com RF)\n",
      "{'accuracy': 0.85, 'specificity': 0.85, 'recall': 0.85, 'precision': 0.85, 'f1-score': 0.85, 'kappa': 0.7, 'auc-roc': 0.85}\n",
      "Métricas para InceptionV3: (Com RF)\n",
      "{'accuracy': 0.725, 'specificity': 0.9, 'recall': 0.55, 'precision': 0.8461538461538461, 'f1-score': 0.6666666666666667, 'kappa': 0.44999999999999996, 'auc-roc': 0.725}\n",
      "Métricas para EfficientNetB0: (Com RF)\n",
      "{'accuracy': 0.85, 'specificity': 0.9, 'recall': 0.8, 'precision': 0.8888888888888888, 'f1-score': 0.8421052631578948, 'kappa': 0.7, 'auc-roc': 0.8500000000000001}\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Métricas para MobileNetV2: (Com RF)\n",
      "{'accuracy': 0.7, 'specificity': 0.65, 'recall': 0.75, 'precision': 0.6818181818181818, 'f1-score': 0.7142857142857143, 'kappa': 0.4, 'auc-roc': 0.7}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNN</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>kappa</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EfficientNetB0</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CNN  accuracy  specificity  recall  precision  f1-score  kappa  \\\n",
       "0           VGG16     0.850         0.80    0.90   0.818182  0.857143   0.70   \n",
       "1        ResNet50     0.850         0.85    0.85   0.850000  0.850000   0.70   \n",
       "2     InceptionV3     0.725         0.90    0.55   0.846154  0.666667   0.45   \n",
       "3  EfficientNetB0     0.850         0.90    0.80   0.888889  0.842105   0.70   \n",
       "4     MobileNetV2     0.700         0.65    0.75   0.681818  0.714286   0.40   \n",
       "\n",
       "   auc-roc  \n",
       "0    0.850  \n",
       "1    0.850  \n",
       "2    0.725  \n",
       "3    0.850  \n",
       "4    0.700  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mapping = {\n",
    "    'VGG16': VGG16,\n",
    "    'ResNet50': ResNet50,\n",
    "    'InceptionV3': InceptionV3,\n",
    "    'EfficientNetB0': EfficientNetB0,\n",
    "    'MobileNetV2': MobileNetV2\n",
    "}\n",
    "\n",
    "\n",
    "tds_Cnns = ['VGG16', 'ResNet50', 'InceptionV3', 'EfficientNetB0', 'MobileNetV2']\n",
    "df_all_metrics = pd.DataFrame()\n",
    "for CNN in tds_Cnns:\n",
    "\n",
    "    # Carregar o modelo InceptionV3 pré-treinado\n",
    "    base_model = model_mapping[CNN](weights='imagenet', include_top=False)     # <----------------------------------------------------------\n",
    "\n",
    "    # Extrair características usando o modelo VGG16\n",
    "    def extract_features(model, X):\n",
    "        features = model.predict(X)\n",
    "        return features.reshape((features.shape[0], -1))\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Carregamento de imagens e conversão para XYZ\n",
    "    normal_images = load_images(normal_dir, 'grayscale',img_extensions)        # <----------------------------------------------------------\n",
    "    cancer_images = load_images(cancer_dir, 'grayscale',img_extensions)        # hsv<----------------------------------------------------------\n",
    "\n",
    "\n",
    "    # Rótulos para imagens (0 para normal, 1 para câncer)\n",
    "    normal_labels = np.zeros(normal_images.shape[0])\n",
    "    cancer_labels = np.ones(cancer_images.shape[0])\n",
    "\n",
    "    # Concatenar imagens e rótulos\n",
    "    all_images = np.concatenate([normal_images, cancer_images], axis=0)\n",
    "    all_images = extract_features(base_model, all_images)\n",
    "    all_labels = np.concatenate([normal_labels, cancer_labels], axis=0)\n",
    "\n",
    "    # Dividir o conjunto de dados em treino e teste (80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=41)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    # Para o SVM\n",
    "    svm_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    metrics_svm = get_metrics(y_test, y_pred_svm)\n",
    "    print(f\"Métricas para {CNN}: (Com RF)\")\n",
    "    print(metrics_svm)\n",
    "\n",
    "\n",
    "\n",
    "    # Criar DataFrames e salvar os resultados em um xlsx \n",
    "    df_metrics_svm = pd.DataFrame([metrics_svm.values()], columns=metrics_svm.keys())\n",
    "    df_metrics_svm.insert(0, 'CNN', CNN)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Concatenar todos os DataFrames\n",
    "    df_all_metrics = pd.concat([df_all_metrics,df_metrics_svm], ignore_index=True)\n",
    "\n",
    "# Salvar o DataFrame em um arquivo Excel\n",
    "df_all_metrics.to_excel('ResultaadoCNN-RF.xlsx', index=False)  # <----------------------------------------------------------\n",
    "\n",
    "df_all_metrics\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
