{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855e4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, InceptionV3, EfficientNetB0, Xception, MobileNetV2\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77308a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para calcular as métricas\n",
    "def get_metrics(y_true, y_pred):\n",
    "    vn, fp, fn, vp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = (vp + vn) / (vp + fp + fn + vn)\n",
    "    recall = vp / (vp + fn)\n",
    "    specificity = vn / (vn + fp)\n",
    "    precision = vp / (vp + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'specificity': specificity,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1-score': f1,\n",
    "        'kappa': kappa,\n",
    "        'auc-roc': auc_roc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4672f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para seleção de esquema de cor \n",
    "def convert_color_scale(image, scale):\n",
    "    if scale == 'hsv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif scale == 'rgb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif scale == 'grayscale':\n",
    "        # Converter para escala de cinza e replicar para 3 canais\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.merge([gray, gray, gray])\n",
    "    elif scale == 'lab':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    elif scale == 'luv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif scale == 'xyz':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2XYZ)\n",
    "    elif scale == 'YcrCb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Escala de cor não suportada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c6ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e pré-processamento de imagens com escolha de escala de cor\n",
    "def load_images(folder, color_scale, img_extensions):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if any(filename.lower().endswith(ext) for ext in img_extensions):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # Ajuste o tamanho conforme necessário\n",
    "\n",
    "                # Converta para a escala de cor desejada\n",
    "                img = convert_color_scale(img, color_scale)\n",
    "\n",
    "                # Se a imagem estiver em escala de cinza, expanda as dimensões\n",
    "                if color_scale == 'grayscale':\n",
    "                    img = np.expand_dims(img, axis=-1)  # Adiciona uma dimensão de canal\n",
    "\n",
    "                images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582c5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina as pastas de dados\n",
    "data_dir = r\"C:\\Users\\andre\\Pictures\\OvarianCancer\"\n",
    "normal_dir = os.path.join(data_dir, 'Non_Cancerous')\n",
    "Serous= os.path.join(data_dir, 'Serous')\n",
    "Mucinous = os.path.join(data_dir, 'Mucinous')\n",
    "Endometrioid = os.path.join(data_dir, 'Endometri')\n",
    "Clear = os.path.join(data_dir, 'Clear_Cell')\n",
    "img_extensions = ['.jpg', '.jpeg', '.png']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacc9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo InceptionV3 pré-treinado\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False)     # <----------------------------------------------------------\n",
    "\n",
    "# Extrair características usando o modelo VGG16\n",
    "def extract_features(model, X):\n",
    "    features = model.predict(X)\n",
    "    features_flat = features.reshape((features.shape[0], -1))\n",
    "    # np.savetxt(\"features_5Classes.csv\", features_flat, delimiter=\",\")\n",
    "    return features_flat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450f29b",
   "metadata": {},
   "source": [
    "## <span style=\"color:green;\">a partir daqui, complica a situação</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc261eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento de imagens e conversão para XYZ\n",
    "normal_images = load_images(normal_dir, 'grayscale',img_extensions)       \n",
    "serous_images = load_images(Serous, 'grayscale',img_extensions)        \n",
    "mucinous_images = load_images(Mucinous, 'grayscale',img_extensions)        \n",
    "endometrioid_images = load_images(Endometrioid, 'grayscale',img_extensions)        \n",
    "clear_images = load_images(Clear, 'grayscale',img_extensions)   \n",
    "\n",
    "\n",
    "#      ISSO SERIA SO PRA 2 CLASSES\n",
    "# Rótulos para imagens (0 para normal, 1 para câncer)\n",
    "# normal_labels = np.zeros(normal_images.shape[0])\n",
    "# cancer_labels = np.ones(cancer_images.shape[0])\n",
    "\n",
    "# # Concatenar imagens e rótulos\n",
    "# all_images = np.concatenate([normal_images, cancer_images], axis=0)\n",
    "# all_images = extract_features(base_model, all_images)\n",
    "# all_labels = np.concatenate([normal_labels, cancer_labels], axis=0)\n",
    "\n",
    "\n",
    "# Rótulos para imagens (0 para normal, 1 para seroso, 2 para mucinoso, 3 para endometrioide, 4 para células claras)\n",
    "y = (\n",
    "    ['Non_Cancerous'] * len(normal_images) +\n",
    "    ['Serous'] * len(serous_images) +\n",
    "    ['Mucinous'] * len(mucinous_images) +\n",
    "    ['Endometrioid'] * len(endometrioid_images) +\n",
    "    ['Clear_Cell'] * len(clear_images)\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "all_images = np.concatenate([\n",
    "    normal_images,\n",
    "    serous_images,\n",
    "    mucinous_images,\n",
    "    endometrioid_images,\n",
    "    clear_images\n",
    "], axis=0)\n",
    "all_images = extract_features(base_model, all_images)\n",
    "\n",
    "\n",
    "\n",
    "# Dividi em treino e teste 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3446a",
   "metadata": {},
   "source": [
    "# testar ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d97c00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.2803 - accuracy: 0.9187 - val_loss: 0.1272 - val_accuracy: 0.9657\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1264 - accuracy: 0.9617 - val_loss: 0.0956 - val_accuracy: 0.9737\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0863 - accuracy: 0.9744 - val_loss: 0.0861 - val_accuracy: 0.9762\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.0660 - accuracy: 0.9801 - val_loss: 0.0810 - val_accuracy: 0.9783\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0829 - val_accuracy: 0.9758\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0796 - accuracy: 0.9759\n",
      "Acurácia no teste: 0.98\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Carregar os dados\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizar os dados\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Converter os rótulos para one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Criar o modelo\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),         # transforma a imagem em vetor\n",
    "    Dense(128, activation='relu'),         # camada oculta\n",
    "    Dense(10, activation='softmax')        # saída para 10 classes (0 a 9)\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n",
    "\n",
    "# Avaliar o modelo\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Acurácia no teste: {test_acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
