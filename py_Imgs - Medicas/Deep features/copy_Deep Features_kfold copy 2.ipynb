{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, InceptionV3, EfficientNetB0, Xception, MobileNetV2\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77308a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para calcular as métricas\n",
    "def get_metrics(y_true, y_pred):\n",
    "    vn, fp, fn, vp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = (vp + vn) / (vp + fp + fn + vn)\n",
    "    recall = vp / (vp + fn)\n",
    "    specificity = vn / (vn + fp)\n",
    "    precision = vp / (vp + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'specificity': specificity,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1-score': f1,\n",
    "        'kappa': kappa,\n",
    "        'auc-roc': auc_roc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4672f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para seleção de esquema de cor \n",
    "def convert_color_scale(image, scale):\n",
    "    if scale == 'hsv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif scale == 'rgb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif scale == 'grayscale':\n",
    "        # Converter para escala de cinza e replicar para 3 canais\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.merge([gray, gray, gray])\n",
    "    elif scale == 'lab':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    elif scale == 'luv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif scale == 'xyz':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2XYZ)\n",
    "    elif scale == 'YcrCb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Escala de cor não suportada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c6ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e pré-processamento de imagens com escolha de escala de cor\n",
    "def load_images(folder, color_scale, img_extensions):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if any(filename.lower().endswith(ext) for ext in img_extensions):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # Ajuste o tamanho conforme necessário\n",
    "\n",
    "                # Converta para a escala de cor desejada\n",
    "                img = convert_color_scale(img, color_scale)\n",
    "\n",
    "                # Se a imagem estiver em escala de cinza, expanda as dimensões\n",
    "                if color_scale == 'grayscale':\n",
    "                    img = np.expand_dims(img, axis=-1)  # Adiciona uma dimensão de canal\n",
    "\n",
    "                images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582c5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina as pastas de dados\n",
    "data_dir = r\"C:\\Users\\andre\\Pictures\\OvarianCancer\"\n",
    "normal_dir = os.path.join(data_dir, 'Non_Cancerous')\n",
    "cancer_dir = os.path.join(data_dir, 'Serous')\n",
    "img_extensions = ['.jpg', '.jpeg', '.png']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91fe6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame para armazenar os resultados\n",
    "columns = ['Modelo', 'Acuracia', 'Sensibilidade', 'Especificidade', 'F-Score', 'AUC-ROC']\n",
    "df_metrics = pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bacc9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo InceptionV3 pré-treinado\n",
    "base_model = VGG16(weights='imagenet', include_top=False)     # <----------------------------------------------------------\n",
    "\n",
    "# Extrair características usando o modelo VGG16\n",
    "def extract_features(model, X):\n",
    "    features = model.predict(X)\n",
    "    return features.reshape((features.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc261eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento de imagens e conversão para XYZ\n",
    "normal_images = load_images(normal_dir, 'grayscale',img_extensions)        # <----------------------------------------------------------\n",
    "cancer_images = load_images(cancer_dir, 'grayscale',img_extensions)        # hsv<----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Rótulos para imagens (0 para normal, 1 para câncer)\n",
    "normal_labels = np.zeros(normal_images.shape[0])\n",
    "cancer_labels = np.ones(cancer_images.shape[0])\n",
    "\n",
    "# Concatenar imagens e rótulos\n",
    "all_images = np.concatenate([normal_images, cancer_images], axis=0)\n",
    "all_images = extract_features(base_model, all_images)\n",
    "all_labels = np.concatenate([normal_labels, cancer_labels], axis=0)\n",
    "\n",
    "# Dividir o conjunto de dados em treino e teste (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab69e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para SVM:\n",
      "{'accuracy': 0.95, 'specificity': 0.9523809523809523, 'recall': 0.9473684210526315, 'precision': 0.9473684210526315, 'f1-score': 0.9473684210526315, 'kappa': 0.899749373433584, 'auc-roc': 0.9498746867167918}\n",
      "Métricas para Random Forest:\n",
      "{'accuracy': 0.925, 'specificity': 0.9523809523809523, 'recall': 0.8947368421052632, 'precision': 0.9444444444444444, 'f1-score': 0.918918918918919, 'kappa': 0.8492462311557789, 'auc-roc': 0.9235588972431078}\n",
      "Métricas para K-Nearest Neighbors (KNN):\n",
      "{'accuracy': 0.75, 'specificity': 0.6666666666666666, 'recall': 0.8421052631578947, 'precision': 0.6956521739130435, 'f1-score': 0.761904761904762, 'kappa': 0.5037220843672456, 'auc-roc': 0.7543859649122807}\n",
      "Métricas para AdaBoost (Gradient Boosting):\n",
      "{'accuracy': 0.95, 'specificity': 1.0, 'recall': 0.8947368421052632, 'precision': 1.0, 'f1-score': 0.9444444444444444, 'kappa': 0.8992443324937027, 'auc-roc': 0.9473684210526316}\n",
      "Métricas para XGBoost:\n",
      "{'accuracy': 0.925, 'specificity': 0.9523809523809523, 'recall': 0.8947368421052632, 'precision': 0.9444444444444444, 'f1-score': 0.918918918918919, 'kappa': 0.8492462311557789, 'auc-roc': 0.9235588972431078}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classificador</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>kappa</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.899749</td>\n",
       "      <td>0.949875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.849246</td>\n",
       "      <td>0.923559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.503722</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.899244</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.849246</td>\n",
       "      <td>0.923559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classificador  accuracy  specificity    recall  precision  f1-score  \\\n",
       "0           SVM     0.950     0.952381  0.947368   0.947368  0.947368   \n",
       "0            RF     0.925     0.952381  0.894737   0.944444  0.918919   \n",
       "0           KNN     0.750     0.666667  0.842105   0.695652  0.761905   \n",
       "0      AdaBoost     0.950     1.000000  0.894737   1.000000  0.944444   \n",
       "0       XGBoost     0.925     0.952381  0.894737   0.944444  0.918919   \n",
       "\n",
       "      kappa   auc-roc  \n",
       "0  0.899749  0.949875  \n",
       "0  0.849246  0.923559  \n",
       "0  0.503722  0.754386  \n",
       "0  0.899244  0.947368  \n",
       "0  0.849246  0.923559  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classificação com 5 classificadores\n",
    "# Para o SVM\n",
    "svm_model = SVC(random_state=42, kernel='rbf', C=1, gamma='scale')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "metrics_svm = get_metrics(y_test, y_pred_svm)\n",
    "print(\"Métricas para SVM:\")\n",
    "print(metrics_svm)\n",
    "\n",
    "# Para o Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "metrics_rf = get_metrics(y_test, y_pred_rf)\n",
    "print(\"Métricas para Random Forest:\")\n",
    "print(metrics_rf)\n",
    "\n",
    "# Para o KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "metrics_knn = get_metrics(y_test, y_pred_knn)\n",
    "print(\"Métricas para K-Nearest Neighbors (KNN):\")\n",
    "print(metrics_knn)\n",
    "\n",
    "# Para o AdaBoost\n",
    "adaboost_model = AdaBoostClassifier(random_state=42, n_estimators=50, learning_rate=1.0)#  random_state=42, n_estimators=100, learning_rate=0.1\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "y_pred_adaboost = adaboost_model.predict(X_test)\n",
    "metrics_adaboost = get_metrics(y_test, y_pred_adaboost)\n",
    "print(\"Métricas para AdaBoost (Gradient Boosting):\")\n",
    "print(metrics_adaboost)\n",
    "\n",
    "# Para o XGB\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42, max_depth=9, \n",
    "                              colsample_bytree=0.4033, min_child_weight=6, gamma=0.429, \n",
    "                              eta=0.5995, n_estimators=1000, use_label_encoder=False, \n",
    "                              eval_metric='merror')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "metrics_xgb = get_metrics(y_test, y_pred_xgb)\n",
    "print(\"Métricas para XGBoost:\")\n",
    "print(metrics_xgb)\n",
    "\n",
    "# Criar DataFrames e salvar os resultados em um xlsx \n",
    "df_metrics_svm = pd.DataFrame([metrics_svm.values()], columns=metrics_svm.keys())\n",
    "df_metrics_svm.insert(0, 'Classificador', 'SVM')\n",
    "\n",
    "df_metrics_rf = pd.DataFrame([metrics_rf.values()], columns=metrics_rf.keys())\n",
    "df_metrics_rf.insert(0, 'Classificador', 'RF')\n",
    "\n",
    "df_metrics_knn = pd.DataFrame([metrics_knn.values()], columns=metrics_knn.keys())\n",
    "df_metrics_knn.insert(0, 'Classificador', 'KNN')\n",
    "\n",
    "df_metrics_adaboost = pd.DataFrame([metrics_adaboost.values()], columns=metrics_adaboost.keys())\n",
    "df_metrics_adaboost.insert(0, 'Classificador', 'AdaBoost')\n",
    "\n",
    "df_metrics_xgb = pd.DataFrame([metrics_xgb.values()], columns=metrics_xgb.keys())\n",
    "df_metrics_xgb.insert(0, 'Classificador', 'XGBoost')\n",
    "\n",
    "# Concatenar todos os DataFrames\n",
    "df_all_metrics = pd.concat([df_metrics_svm, df_metrics_rf, df_metrics_knn, df_metrics_adaboost, df_metrics_xgb])\n",
    "\n",
    "# Salvar o DataFrame em um arquivo Excel\n",
    "'df_all_metrics.to_excel('testando.xlsx', index=False)  # <----------------------------------------------------------\n",
    "\n",
    "df_all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bbaf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para cada fold:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>kappa</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.876263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.847716</td>\n",
       "      <td>0.927110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.889037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Média</th>\n",
       "      <td>0.899487</td>\n",
       "      <td>0.875092</td>\n",
       "      <td>0.920293</td>\n",
       "      <td>0.893730</td>\n",
       "      <td>0.902845</td>\n",
       "      <td>0.796712</td>\n",
       "      <td>0.897693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desvio Padrão</th>\n",
       "      <td>0.025026</td>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.065738</td>\n",
       "      <td>0.071719</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  specificity    recall  precision  f1-score     kappa  \\\n",
       "0              0.925000     1.000000  0.842105   1.000000  0.914286  0.848485   \n",
       "1              0.875000     0.888889  0.863636   0.904762  0.883721  0.748744   \n",
       "2              0.875000     0.750000  1.000000   0.800000  0.888889  0.750000   \n",
       "3              0.925000     0.913043  0.941176   0.888889  0.914286  0.847716   \n",
       "4              0.897436     0.823529  0.954545   0.875000  0.913043  0.788618   \n",
       "Média          0.899487     0.875092  0.920293   0.893730  0.902845  0.796712   \n",
       "Desvio Padrão  0.025026     0.094259  0.065738   0.071719  0.015218  0.049574   \n",
       "\n",
       "                auc-roc  \n",
       "0              0.921053  \n",
       "1              0.876263  \n",
       "2              0.875000  \n",
       "3              0.927110  \n",
       "4              0.889037  \n",
       "Média          0.897693  \n",
       "Desvio Padrão  0.024800  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defina o número de splits para a validação cruzada\n",
    "from sklearn.model_selection import KFold\n",
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Crie uma lista para armazenar os resultados de cada fold\n",
    "metrics_list = []\n",
    "\n",
    "X = all_images\n",
    "y = all_labels\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    # Divida os dados em treino e teste\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Crie e treine o modelo\n",
    "    svm_model =SVC(random_state=42, kernel='rbf', C=1, gamma='scale')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faça a predição\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calcule as métricas\n",
    "    metrics = get_metrics(y_test, y_pred)\n",
    "    metrics_list.append(metrics)\n",
    "\n",
    "# Crie um DataFrame para armazenar os resultados de cada fold\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calcule a média e o desvio padrão\n",
    "mean_metrics = metrics_df.mean()\n",
    "std_metrics = metrics_df.std()\n",
    "\n",
    "# Adicione as linhas de média e desvio padrão ao DataFrame\n",
    "metrics_df.loc['Média'] = mean_metrics\n",
    "metrics_df.loc['Desvio Padrão'] = std_metrics\n",
    "\n",
    "print(\"Métricas para cada fold:\")\n",
    "metrics_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334432b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maior_acc_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6bef7aabb56a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# menor=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mmaior_acc_test\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m0.92\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'maior_acc_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# menor=1\n",
    "while maior_acc_test <0.92:\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(all_images, all_labels,test_size=0.1)\n",
    "\n",
    "\n",
    "\n",
    "  k_range = list(range(1, 30))\n",
    "\n",
    "  maior_k = 0.0\n",
    "  maior_acc_test = 0.0\n",
    "\n",
    "  # print(\"k\\t\\tAcc Test\\t\\tAcc Train\")\n",
    "\n",
    "  for k in k_range:\n",
    "      knn = KNeighborsClassifier(n_neighbors=k)\n",
    "      knn = knn.fit(X_train, Y_train)\n",
    "      acc_test = knn.score(X_test, Y_test)\n",
    "      acc_train = knn.score(X_train, Y_train)\n",
    "      \n",
    "      if acc_test > maior_acc_test:\n",
    "          maior_k = k\n",
    "          maior_acc_test = acc_test\n",
    "\n",
    "    #   if acc_test <menor:\n",
    "    #      menor = acc_test\n",
    "      \n",
    "      # print(str(k)+\"\\t\\t\"+str(acc_test)+\"\\t\\t\"+str(acc_train))\n",
    "if maior_acc_test>=0.8:\n",
    "#   print(\"variaçaão\",maior_acc_test-menor)\n",
    "  print(\"Maior valor de K é\", maior_k, \"com acurácia em teste igual a\", maior_acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e9be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) D:\\bld\\libopencv_1632857399304\\work\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1a435dd7698a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'CAMINHO_DA_IMAGEM'\u001b[0m  \u001b[1;31m# Substituir pelo caminho da imagem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Ajustar ao tamanho esperado pelo modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) D:\\bld\\libopencv_1632857399304\\work\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def get_gradcam(model, img_array, layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.input, \n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 1]  # Supondo que a classe positiva (câncer) seja o índice 1\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1).numpy().squeeze()\n",
    "    heatmap = np.maximum(heatmap, 0)  # ReLU\n",
    "    heatmap /= np.max(heatmap)  # Normalizar\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def overlay_heatmap(img, heatmap, alpha=0.4):\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    overlayed = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
    "    return overlayed\n",
    "\n",
    "# Exemplo de uso\n",
    "img_path = r\"C:\\Users\\andre\\Pictures\\OvarianCancer\\Serous\\high gradw serous.JPG\"  # Substituir pelo caminho da imagem\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_array = cv2.resize(img, (224, 224))  # Ajustar ao tamanho esperado pelo modelo\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "layer_name = 'block5_conv3'  # Substituir por uma camada convolucional do modelo usado\n",
    "heatmap = get_gradcam(base_model, img_array, layer_name)\n",
    "overlayed_img = overlay_heatmap(img, heatmap)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Imagem Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(overlayed_img)\n",
    "plt.title(\"Grad-CAM\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a524a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-719471cec16a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\andre\\Documents\\atividades\\estudos_opencv\\py_Imgs - Medicas\\06-separando_ComBasenosNomes\\07 - extração e classificação\\modelo.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
