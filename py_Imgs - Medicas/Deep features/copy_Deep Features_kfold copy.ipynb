{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855e4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, InceptionV3, EfficientNetB0, Xception, MobileNetV2\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "#testar com todos  'EfficientNetB0'\n",
    "# rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77308a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para calcular as métricas\n",
    "def get_metrics(y_true, y_pred):\n",
    "    vn, fp, fn, vp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = (vp + vn) / (vp + fp + fn + vn)\n",
    "    recall = vp / (vp + fn)\n",
    "    specificity = vn / (vn + fp)\n",
    "    precision = vp / (vp + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'specificity': specificity,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1-score': f1,\n",
    "        'kappa': kappa,\n",
    "        'auc-roc': auc_roc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4672f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para seleção de esquema de cor \n",
    "def convert_color_scale(image, scale):\n",
    "    if scale == 'hsv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif scale == 'rgb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif scale == 'grayscale':\n",
    "        # Converter para escala de cinza e replicar para 3 canais\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.merge([gray, gray, gray])\n",
    "    elif scale == 'lab':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    elif scale == 'luv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif scale == 'xyz':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2XYZ)\n",
    "    elif scale == 'YcrCb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Escala de cor não suportada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c6ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e pré-processamento de imagens com escolha de escala de cor\n",
    "def load_images(folder, color_scale, img_extensions):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if any(filename.lower().endswith(ext) for ext in img_extensions):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # Ajuste o tamanho conforme necessário\n",
    "\n",
    "                # Converta para a escala de cor desejada\n",
    "                img = convert_color_scale(img, color_scale)\n",
    "\n",
    "                # Se a imagem estiver em escala de cinza, expanda as dimensões\n",
    "                if color_scale == 'grayscale':\n",
    "                    img = np.expand_dims(img, axis=-1)  # Adiciona uma dimensão de canal\n",
    "\n",
    "                images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582c5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina as pastas de dados\n",
    "data_dir = r\"C:\\Users\\andre\\Pictures\\OvarianCancer\"\n",
    "normal_dir = os.path.join(data_dir, 'Non_Cancerous')\n",
    "cancer_dir = os.path.join(data_dir, 'Serous')\n",
    "img_extensions = ['.jpg', '.jpeg', '.png']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91fe6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame para armazenar os resultados\n",
    "columns = ['Modelo', 'Acuracia', 'Sensibilidade', 'Especificidade', 'F-Score', 'AUC-ROC']\n",
    "df_metrics = pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacc9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo InceptionV3 pré-treinado\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False)     # <----------------------------------------------------------\n",
    "\n",
    "# Extrair características usando o modelo VGG16\n",
    "def extract_features(model, X):\n",
    "    features = model.predict(X)\n",
    "    return features.reshape((features.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bc261eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento de imagens e conversão para XYZ\n",
    "normal_images = load_images(normal_dir, 'hsv',img_extensions)        # <----------------------------------------------------------\n",
    "cancer_images = load_images(cancer_dir, 'hsv',img_extensions)        # hsv<----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Rótulos para imagens (0 para normal, 1 para câncer)\n",
    "normal_labels = np.zeros(normal_images.shape[0])\n",
    "cancer_labels = np.ones(cancer_images.shape[0])\n",
    "\n",
    "# Concatenar imagens e rótulos\n",
    "all_images = np.concatenate([normal_images, cancer_images], axis=0)\n",
    "all_images = extract_features(base_model, all_images)\n",
    "all_labels = np.concatenate([normal_labels, cancer_labels], axis=0)\n",
    "\n",
    "# Dividir o conjunto de dados em treino e teste (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ab69e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para SVM:\n",
      "{'accuracy': 0.95, 'specificity': 0.9523809523809523, 'recall': 0.9473684210526315, 'precision': 0.9473684210526315, 'f1-score': 0.9473684210526315, 'kappa': 0.899749373433584, 'auc-roc': 0.9498746867167918}\n",
      "Métricas para Random Forest:\n",
      "{'accuracy': 0.9, 'specificity': 0.9523809523809523, 'recall': 0.8421052631578947, 'precision': 0.9411764705882353, 'f1-score': 0.8888888888888888, 'kappa': 0.7984886649874056, 'auc-roc': 0.8972431077694235}\n",
      "Métricas para K-Nearest Neighbors (KNN):\n",
      "{'accuracy': 0.75, 'specificity': 0.6666666666666666, 'recall': 0.8421052631578947, 'precision': 0.6956521739130435, 'f1-score': 0.761904761904762, 'kappa': 0.5037220843672456, 'auc-roc': 0.7543859649122807}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-fc4469ec56e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Para o AdaBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0madaboost_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#  random_state=42, n_estimators=100, learning_rate=0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0madaboost_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0my_pred_adaboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madaboost_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmetrics_adaboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_adaboost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\TFenv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\TFenv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\TFenv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \"\"\"\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\TFenv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\TFenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    908\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\andre\\anaconda3\\envs\\TFenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Classificação com 5 classificadores\n",
    "# Para o SVM\n",
    "svm_model = SVC(random_state=42, kernel='rbf', C=1, gamma='scale')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "metrics_svm = get_metrics(y_test, y_pred_svm)\n",
    "print(\"Métricas para SVM:\")\n",
    "print(metrics_svm)\n",
    "\n",
    "# Para o Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "metrics_rf = get_metrics(y_test, y_pred_rf)\n",
    "print(\"Métricas para Random Forest:\")\n",
    "print(metrics_rf)\n",
    "\n",
    "# Para o KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "metrics_knn = get_metrics(y_test, y_pred_knn)\n",
    "print(\"Métricas para K-Nearest Neighbors (KNN):\")\n",
    "print(metrics_knn)\n",
    "\n",
    "# Para o AdaBoost\n",
    "adaboost_model = AdaBoostClassifier(random_state=42, n_estimators=50, learning_rate=1.0)#  random_state=42, n_estimators=100, learning_rate=0.1\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "y_pred_adaboost = adaboost_model.predict(X_test)\n",
    "metrics_adaboost = get_metrics(y_test, y_pred_adaboost)\n",
    "print(\"Métricas para AdaBoost (Gradient Boosting):\")\n",
    "print(metrics_adaboost)\n",
    "\n",
    "# Para o XGB\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42, max_depth=9, \n",
    "                              colsample_bytree=0.4033, min_child_weight=6, gamma=0.429, \n",
    "                              eta=0.5995, n_estimators=1000, use_label_encoder=False, \n",
    "                              eval_metric='merror')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "metrics_xgb = get_metrics(y_test, y_pred_xgb)\n",
    "print(\"Métricas para XGBoost:\")\n",
    "print(metrics_xgb)\n",
    "\n",
    "# Criar DataFrames e salvar os resultados em um xlsx \n",
    "df_metrics_svm = pd.DataFrame([metrics_svm.values()], columns=metrics_svm.keys())\n",
    "df_metrics_svm.insert(0, 'Classificador', 'SVM')\n",
    "\n",
    "df_metrics_rf = pd.DataFrame([metrics_rf.values()], columns=metrics_rf.keys())\n",
    "df_metrics_rf.insert(0, 'Classificador', 'RF')\n",
    "\n",
    "df_metrics_knn = pd.DataFrame([metrics_knn.values()], columns=metrics_knn.keys())\n",
    "df_metrics_knn.insert(0, 'Classificador', 'KNN')\n",
    "\n",
    "df_metrics_adaboost = pd.DataFrame([metrics_adaboost.values()], columns=metrics_adaboost.keys())\n",
    "df_metrics_adaboost.insert(0, 'Classificador', 'AdaBoost')\n",
    "\n",
    "df_metrics_xgb = pd.DataFrame([metrics_xgb.values()], columns=metrics_xgb.keys())\n",
    "df_metrics_xgb.insert(0, 'Classificador', 'XGBoost')\n",
    "\n",
    "# Concatenar todos os DataFrames\n",
    "df_all_metrics = pd.concat([df_metrics_svm, df_metrics_rf, df_metrics_knn, df_metrics_adaboost, df_metrics_xgb])\n",
    "\n",
    "# Salvar o DataFrame em um arquivo Excel\n",
    "df_all_metrics.to_excel('testando.xlsx', index=False)     # <----------------------------------------------------------\n",
    "\n",
    "df_all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bbaf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para cada fold:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>kappa</th>\n",
       "      <th>auc-roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.694656</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.753695</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.746193</td>\n",
       "      <td>0.875959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.539974</td>\n",
       "      <td>0.775401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Média</th>\n",
       "      <td>0.823846</td>\n",
       "      <td>0.878619</td>\n",
       "      <td>0.773313</td>\n",
       "      <td>0.880542</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.646904</td>\n",
       "      <td>0.825966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desvio Padrão</th>\n",
       "      <td>0.059903</td>\n",
       "      <td>0.126973</td>\n",
       "      <td>0.075268</td>\n",
       "      <td>0.118044</td>\n",
       "      <td>0.047441</td>\n",
       "      <td>0.118909</td>\n",
       "      <td>0.060695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  specificity    recall  precision  f1-score     kappa  \\\n",
       "0              0.850000     1.000000  0.684211   1.000000  0.812500  0.694656   \n",
       "1              0.875000     1.000000  0.772727   1.000000  0.871795  0.753695   \n",
       "2              0.750000     0.700000  0.800000   0.727273  0.761905  0.500000   \n",
       "3              0.875000     0.869565  0.882353   0.833333  0.857143  0.746193   \n",
       "4              0.769231     0.823529  0.727273   0.842105  0.780488  0.539974   \n",
       "Média          0.823846     0.878619  0.773313   0.880542  0.816766  0.646904   \n",
       "Desvio Padrão  0.059903     0.126973  0.075268   0.118044  0.047441  0.118909   \n",
       "\n",
       "                auc-roc  \n",
       "0              0.842105  \n",
       "1              0.886364  \n",
       "2              0.750000  \n",
       "3              0.875959  \n",
       "4              0.775401  \n",
       "Média          0.825966  \n",
       "Desvio Padrão  0.060695  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defina o número de splits para a validação cruzada\n",
    "from sklearn.model_selection import KFold\n",
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Crie uma lista para armazenar os resultados de cada fold\n",
    "metrics_list = []\n",
    "\n",
    "X = all_images\n",
    "y = all_labels\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    # Divida os dados em treino e teste\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Crie e treine o modelo\n",
    "    svm_model =AdaBoostClassifier(random_state=42, n_estimators=50, learning_rate=1.0)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faça a predição\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calcule as métricas\n",
    "    metrics = get_metrics(y_test, y_pred)\n",
    "    metrics_list.append(metrics)\n",
    "\n",
    "# Crie um DataFrame para armazenar os resultados de cada fold\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calcule a média e o desvio padrão\n",
    "mean_metrics = metrics_df.mean()\n",
    "std_metrics = metrics_df.std()\n",
    "\n",
    "# Adicione as linhas de média e desvio padrão ao DataFrame\n",
    "metrics_df.loc['Média'] = mean_metrics\n",
    "metrics_df.loc['Desvio Padrão'] = std_metrics\n",
    "\n",
    "print(\"Métricas para cada fold:\")\n",
    "metrics_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2334432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maior valor de K é 4 com acurácia em teste igual a 0.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# menor=1\n",
    "while maior_acc_test <0.92:\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(all_images, all_labels,test_size=0.1)\n",
    "\n",
    "\n",
    "\n",
    "  k_range = list(range(1, 30))\n",
    "\n",
    "  maior_k = 0.0\n",
    "  maior_acc_test = 0.0\n",
    "\n",
    "  # print(\"k\\t\\tAcc Test\\t\\tAcc Train\")\n",
    "\n",
    "  for k in k_range:\n",
    "      knn = KNeighborsClassifier(n_neighbors=k)\n",
    "      knn = knn.fit(X_train, Y_train)\n",
    "      acc_test = knn.score(X_test, Y_test)\n",
    "      acc_train = knn.score(X_train, Y_train)\n",
    "      \n",
    "      if acc_test > maior_acc_test:\n",
    "          maior_k = k\n",
    "          maior_acc_test = acc_test\n",
    "\n",
    "    #   if acc_test <menor:\n",
    "    #      menor = acc_test\n",
    "      \n",
    "      # print(str(k)+\"\\t\\t\"+str(acc_test)+\"\\t\\t\"+str(acc_train))\n",
    "if maior_acc_test>=0.8:\n",
    "#   print(\"variaçaão\",maior_acc_test-menor)\n",
    "  print(\"Maior valor de K é\", maior_k, \"com acurácia em teste igual a\", maior_acc_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
