{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d83b6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import tensorflow as tf\n",
    "# 001\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121, InceptionV3, EfficientNetB0, Xception, MobileNetV2\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# 002\n",
    "# from keras._tf_keras.keras.preprocessing.image import  ImageDataGenerator\n",
    "# from keras._tf_keras.keras.applications import VGG16, ResNet50, DenseNet121, InceptionV3, EfficientNetB0, Xception, MobileNetV2\n",
    "# from keras._tf_keras.keras import models, layers, optimizers, callbacks\n",
    "# from keras._tf_keras.keras import backend as K\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c718a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para calcular as métricas\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    vn, fp, fn, vp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = (vp + vn) / (vp + fp + fn + vn)  \n",
    "    recall = vp / (vp + fn)\n",
    "    specificity = vn / (vn + fp)\n",
    "    precision = vp / (vp + fp)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'specificity': specificity,\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1-score': f1,\n",
    "        'kappa': kappa,\n",
    "        'auc-roc': auc_roc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e68a1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para seleção de esquema de cor \n",
    "def convert_color_scale(image, scale):\n",
    "    if scale == 'hsv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif scale == 'rgb':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif scale == 'grayscale':\n",
    "        # Converter para escala de cinza e replicar para 3 canais\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return cv2.merge([gray, gray, gray])\n",
    "    elif scale == 'lab':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    elif scale == 'luv':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif scale == 'xyz':\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2XYZ)\n",
    "    else:\n",
    "        raise ValueError(\"Escala de cor não suportada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e pré-processamento de imagens com escolha de escala de cor\n",
    "\n",
    "def load_images(folder, color_scale, img_extensions):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if any(filename.lower().endswith(ext) for ext in img_extensions):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))  # Ajuste o tamanho conforme necessário\n",
    "                img = convert_color_scale(img, color_scale)  # Converta para a escala de cor desejada\n",
    "                # Se a imagem estiver em escala de cinza, expanda as dimensões\n",
    "                if color_scale == 'grayscale':\n",
    "                    img = np.expand_dims(img, axis=-1)  # Adiciona uma dimensão de canal\n",
    "                images.append(img)\n",
    "\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82d6458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta normal_dir acessada com sucesso.\n",
      "Pasta cancer_dir acessada com sucesso.\n",
      "sim, na pasta normal ha itens\n",
      "sim, na pasta cancer ha itens\n"
     ]
    }
   ],
   "source": [
    "# Defina as pastas de dados\n",
    "data_dir = r\"C:\\Users\\andre\\Downloads\\archive\\OvarianCancer\\\\duas\"\n",
    "normal_dir = os.path.join(data_dir, 'Non_Cancerous')\n",
    "cancer_dir = os.path.join(data_dir, 'Endometri')\n",
    "img_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "if os.path.exists(normal_dir): print(f\"Pasta normal_dir acessada com sucesso.\") \n",
    "else: print(f\"Erro ao acessar a pasta normal_dir.\") \n",
    "if os.path.exists(cancer_dir): print(f\"Pasta cancer_dir acessada com sucesso.\") \n",
    "else: print(f\"Erro ao acessar a pasta cancer_dir.\")\n",
    "\n",
    "if os.listdir(normal_dir):print(\"sim, na pasta normal ha itens\")\n",
    "if os.listdir(cancer_dir):print(\"sim, na pasta cancer ha itens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ded7f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame para armazenar os resultados\n",
    "columns = ['Modelo', 'Acuracia', 'Sensibilidade', 'Especificidade', 'F-Score', 'AUC-ROC']\n",
    "df_metrics = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Definir o caminho para salvar o melhor modelo\n",
    "model_checkpoint_path = r\"C:\\Users\\andre\\Documents\\atividades\\estudos_opencv\\processamento de imagens\\\\best_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c4e428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre os modelos\n",
    "def model_execution(model_name):\n",
    "\n",
    "    # Carregamento de imagens e conversão para XYZ\n",
    "    normal_images = load_images(normal_dir, 'xyz',img_extensions)\n",
    "    cancer_images = load_images(cancer_dir, 'xyz',img_extensions)\n",
    "\n",
    "    # Rótulos para imagens (0 para normal, 1 para câncer)\n",
    "    normal_labels = np.zeros(normal_images.shape[0])\n",
    "    cancer_labels = np.ones(cancer_images.shape[0])\n",
    "\n",
    "    # Concatenar imagens e rótulos\n",
    "    all_images = np.concatenate([normal_images, cancer_images], axis=0)\n",
    "    all_labels = np.concatenate([normal_labels, cancer_labels], axis=0)\n",
    "\n",
    "    # Dividir o conjunto de dados em treino e teste (80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Escolha entre 5 tipos de conversão de escala de cor aqui (por exemplo, normalização)\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    # Escolher o modelo de CNN\n",
    "    if model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'InceptionV3':\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'Xception':\n",
    "        base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'VisionTransformer':\n",
    "            base_model = VitB16(image_size=(224, 224), weights='imagenet', include_top=False)\n",
    "    else:\n",
    "        raise ValueError(\"Modelo de CNN não suportado.\")\n",
    "\n",
    "    # Construir o modelo\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compilar o modelo\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Configurar o retorno de chamada ModelCheckpoint\n",
    "#     checkpoint = callbacks.ModelCheckpoint(model_checkpoint_path,\n",
    "#                                            monitor='val_accuracy',  # Métrica a ser monitorad\n",
    "#                                            mode='max',               # Salvar o modelo com a maior precisão\n",
    "#                                            verbose=1)\n",
    "\n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=16, validation_split=0.2)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calcular métricas\n",
    "    metrics = get_metrics(y_test, y_pred_binary)\n",
    "\n",
    "    # Adicionar as métricas ao DataFrame\n",
    "    metrics['Modelo'] = model_name\n",
    "    \n",
    "    # Excluir o modelo atual para liberar memória da GPU   \n",
    "    del all_images, normal_images, cancer_images, X_train, X_test, y_train, y_test, y_pred, y_pred_binary\n",
    "    del all_labels, normal_labels, cancer_labels\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model, base_model\n",
    "    gc.collect()\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bb40d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m Erro ao carregar a imagem: \u001b[m C:\\Users\\andre\\Downloads\\archive\\OvarianCancer\\\\duas\\Non_Cancerous\\4.jpg\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4s/step - accuracy: 0.6374 - loss: 0.6672 - val_accuracy: 0.6562 - val_loss: 0.6168\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 658ms/step\n",
      "\u001b[31m Erro ao carregar a imagem: \u001b[m C:\\Users\\andre\\Downloads\\archive\\OvarianCancer\\\\duas\\Non_Cancerous\\4.jpg\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4s/step - accuracy: 0.5253 - loss: 0.8440 - val_accuracy: 0.4688 - val_loss: 0.7137\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 617ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24224\\2295546688.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = vp / (vp + fp)\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24224\\823516501.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_metrics = pd.concat([df_metrics, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m Erro ao carregar a imagem: \u001b[m C:\\Users\\andre\\Downloads\\archive\\OvarianCancer\\\\duas\\Non_Cancerous\\4.jpg\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2s/step - accuracy: 0.5647 - loss: 1.4930 - val_accuracy: 0.4375 - val_loss: 1.6570\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24224\\2295546688.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = vp / (vp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m Erro ao carregar a imagem: \u001b[m C:\\Users\\andre\\Downloads\\archive\\OvarianCancer\\\\duas\\Non_Cancerous\\4.jpg\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.6501 - loss: 0.7776 - val_accuracy: 0.5000 - val_loss: 1.0020\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "\u001b[31m Erro ao carregar a imagem: \u001b[m C:\\Users\\andre\\Downloads\\archive\\OvarianCancer\\\\duas\\Non_Cancerous\\4.jpg\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 823ms/step - accuracy: 0.5761 - loss: 1.0244 - val_accuracy: 0.6562 - val_loss: 0.8475\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 696ms/step\n",
      "\u001b[31m Erro ao carregar a imagem: \u001b[m C:\\Users\\andre\\Downloads\\archive\\OvarianCancer\\\\duas\\Non_Cancerous\\4.jpg\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.5790 - loss: 0.8245 - val_accuracy: 0.4375 - val_loss: 1.1585\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24224\\2295546688.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = vp / (vp + fp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acuracia</th>\n",
       "      <th>Sensibilidade</th>\n",
       "      <th>Especificidade</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.555138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.567669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EfficientNetB0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Modelo  Acuracia  Sensibilidade  Especificidade   F-Score   AUC-ROC\n",
       "0           VGG16     0.525       0.000000        1.000000  0.000000  0.500000\n",
       "1        ResNet50     0.525       0.000000        1.000000  0.000000  0.500000\n",
       "2     InceptionV3     0.575       0.157895        0.952381  0.260870  0.555138\n",
       "3     MobileNetV2     0.575       0.421053        0.714286  0.484848  0.567669\n",
       "4  EfficientNetB0     0.525       0.000000        1.000000  0.000000  0.500000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_model = 'VGG16'\n",
    "metrics = model_execution(chosen_model)\n",
    "metrics = model_execution(chosen_model)\n",
    "temp_df = pd.DataFrame([[chosen_model, metrics['accuracy'], metrics['recall'], metrics['specificity'], metrics['f1-score'], metrics['auc-roc']]], columns=columns)  \n",
    "df_metrics = pd.concat([df_metrics, temp_df], ignore_index=True)\n",
    "\n",
    "chosen_model = 'ResNet50'\n",
    "metrics = model_execution(chosen_model)\n",
    "temp_df = pd.DataFrame([[chosen_model, metrics['accuracy'], metrics['recall'], metrics['specificity'], metrics['f1-score'], metrics['auc-roc']]], columns=columns)  \n",
    "df_metrics = pd.concat([df_metrics, temp_df], ignore_index=True)\n",
    "\n",
    "chosen_model = 'InceptionV3'\n",
    "metrics = model_execution(chosen_model)\n",
    "temp_df = pd.DataFrame([[chosen_model, metrics['accuracy'], metrics['recall'], metrics['specificity'], metrics['f1-score'], metrics['auc-roc']]], columns=columns)  \n",
    "df_metrics = pd.concat([df_metrics, temp_df], ignore_index=True)\n",
    "\n",
    "chosen_model = 'MobileNetV2'\n",
    "metrics = model_execution(chosen_model)\n",
    "temp_df = pd.DataFrame([[chosen_model, metrics['accuracy'], metrics['recall'], metrics['specificity'], metrics['f1-score'], metrics['auc-roc']]], columns=columns)  \n",
    "df_metrics = pd.concat([df_metrics, temp_df], ignore_index=True)\n",
    "\n",
    "chosen_model = 'EfficientNetB0'\n",
    "metrics = model_execution(chosen_model)\n",
    "temp_df = pd.DataFrame([[chosen_model, metrics['accuracy'], metrics['recall'], metrics['specificity'], metrics['f1-score'], metrics['auc-roc']]], columns=columns)  \n",
    "df_metrics = pd.concat([df_metrics, temp_df], ignore_index=True)\n",
    "\n",
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
